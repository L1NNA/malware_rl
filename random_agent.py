import os
import sys
import random
import gym
from gym import wrappers
import numpy as np
import h4rm0ny
from IPython import embed
#set seed so we can reproduce experiments
random.seed(0)
#set the mod path for grabbing files
module_path = os.path.split(os.path.abspath(sys.modules[__name__].__file__))[0]

#our random agent class
class RandomAgent(object):
    """The world's simplest agent!"""
    #init, agent has an action space
    def __init__(self, action_space):
        self.action_space = action_space
        
    #act function 
    def act(self, observation, reward, done):
        return self.action_space.sample()


# gym setup
outdir = os.path.join(module_path, 'data/logs/random-agent-results')
#our env is a malconv gym
env = gym.make('malconv-train-v0')
#monitor the gym (?)
env = wrappers.Monitor(env, directory=outdir, force=True)
#set our seed
env.seed(0)
#set the number of episodes (a piece of malware is an episode)
episode_count = 10
# we are not done 
done = False
#default reward 
reward = 0

# metric tracking
evasions = 0
evasion_history = {}
#our agent is a random agent with action space defined in malconv gym
agent = RandomAgent(env.action_space)
#each episode
for i in range(episode_count):
    #reset the gym for the new malware
    ob = env.reset()
    #get the malware list
    sha256 = env.env.sha256
    #obfuscate malware
    while True:
        action = agent.act(ob, reward, done)
        ob, reward, done, ep_history = env.step(action)
        #if malware evaded malconv
        if done and reward >= 10.0:
            #add an evasion to the list
            evasions += 1
            evasion_history[sha256] = ep_history
            break
        #we could not evade, but get out
        elif done:
            break
#evasion rate
evasion_rate = (evasions/episode_count) * 100
#get the expected number of actions
mean_action_count = np.mean(env.get_episode_lengths())
print(f"{evasion_rate}% samples evaded model.")
print(f"Average of {mean_action_count} moves to evade model.")
embed()
